# CNN Convolution Accelerator on PYNQâ€‘Z2

**Author:** Eliot Abramo Â Â 

**Board:** PYNQâ€‘Z2 (xc7z020â€‘clg400â€‘1) Â Â 

**Clock:** 100â€‘125Â MHzÂ Â 

---

```mermaid
graph TD
    subgraph Host
        pyhost[cnn_run.py]
        dma[AXI DMA Driver]
    end

    subgraph ProgrammableLogic
        conv[conv2d_hw Kernel]
    end

    img[[Input Image]] --> pyhost
    pyhost --> dma --> conv
    conv --> dma --> fmap[[Output Feature Map]]
```

---

## ğŸš€ Project Essence

> *One HLS kernel, three caching layers, four output filters computed in lockâ€‘step, and a single burstâ€‘optimised AXI interface â€” all on a 28â€¯nm Zynq fabric.*

| Pillar               | Technique                                                     | Key Code Snippet                                                                |
| -------------------- | ------------------------------------------------------------- | ------------------------------------------------------------------------------- |
| **Memory Bandwidth** | 256â€‘beat AXI bursts, 30â€‘cycle latency                         | `#pragmaÂ HLSÂ INTERFACEÂ m_axiÂ max_read_burst_length=256Â latency=30Â bundle=gmem0` |
| **Filter Locality**  | 4â€‘filter cache (`coeffs[4][256][3][3]`) with cyclic partition | `#pragmaÂ HLSÂ ARRAY_PARTITIONÂ variable=coeffsÂ cyclicÂ factor=4Â dim=1`             |
| **Row Reâ€‘use**       | Triple linebuffers sized to worstâ€‘case (4064)                 | `TFXPÂ linebuffer0[4064];Â // three such buffers`                                 |
| **Throughput**       | Loop fusion + full II=1 pipeline                              | `#pragmaÂ HLSÂ PIPELINEÂ II=1`                                                     |
| **Numerics**         | Fixedâ€‘point `ap_fixed<16,4>` to fit DSP48                     | `typedefÂ ap_fixed<16,4>Â TFXP;`                                                  |

---

## ğŸ” Deep Technical Dive

### 1Â Â Kernel Top Level

```cpp
extern "C" {
void conv2d_hw(
    const TFXP  *in,
    const TFXP  *bias,
    const TFXP  *coeffs,   // packed 4Ã—256Ã—3Ã—3 filters
          TFXP  *out,
    unsigned     in_ch,
    unsigned     out_ch,
    unsigned     H,
    unsigned     W) {
  #pragma HLS INTERFACE m_axi port=in     offset=slave depth=16384 bundle=gmem0
  #pragma HLS INTERFACE m_axi port=out    offset=slave depth=16384 bundle=gmem1
  #pragma HLS INTERFACE m_axi port=coeffs offset=slave depth=9216  bundle=gmem2
  #pragma HLS INTERFACE m_axi port=bias   offset=slave depth=256   bundle=gmem2
  #pragma HLS INTERFACE s_axilite port=return bundle=control
  #pragma HLS PIPELINE II=1
  // ... compute loops shown below ...
}
}
```

*Four M\_AXI ports avoid contention; `gmem2` shares coeff & bias because they are readâ€‘only.*

### 2Â Â Slidingâ€‘Window Convolution Loop (innerâ€‘most)

```cpp
Win: for(int kh=0; kh<3; ++kh)
  for(int kw=0; kw<3; ++kw) {
    #pragma HLS UNROLL factor=3
    acc0 += linebuf0[p_idx+kw] * coeffs[0][c][kh][kw];
    acc1 += linebuf0[p_idx+kw] * coeffs[1][c][kh][kw];
    acc2 += linebuf0[p_idx+kw] * coeffs[2][c][kh][kw];
    acc3 += linebuf0[p_idx+kw] * coeffs[3][c][kh][kw];
  }
```

*Each accumulation updates **four output channels** concurrently, matching the 4â€‘filter cache stride.*

### 3Â Â BiasÂ +Â ReLU Fuse Stage

```cpp
post: for(int f=0; f<4; ++f) {
  TFXP tmp = acc[f] + bias[f];
  out[p_out+f] = (tmp > 0) ? tmp : 0; // ReLU
}
```

*Fusing postâ€‘ops here saves \~2â€¯Âµs per frame and avoids extra BRAM.*

### 4Â Â Hostâ€‘Side DMA Burst Setup (cnn\_run.py)

```python
from pynq import Overlay, allocate
ol = Overlay('conv_accel.bit')
input_buf  = allocate(shape=(H,W,IC), dtype=np.int16, cacheable=1)
output_buf = allocate(shape=(H-2,W-2,OC), dtype=np.int16, cacheable=1)
conv_ip = ol.conv2d_hw_0
conv_ip.write(0x10, input_buf.physical_address)
conv_ip.write(0x18, output_buf.physical_address)
conv_ip.write(0x1C, coeffs_buf.physical_address)
conv_ip.write(0x20, bias_buf.physical_address)
conv_ip.write(0x28, IC)
conv_ip.write(0x2C, OC)
conv_ip.write(0x30, H)
conv_ip.write(0x34, W)
conv_ip.write(0x00, 1)  # start
conv_ip.wait()
```

*PYNQâ€™s zeroâ€‘copy `allocate` ensures physical contiguity for 256â€‘beat bursts.*

---

## ğŸ“Š Benchmark & Resource Table

| Variant      | LatencyÂ (ms) | FreqÂ (MHz) |    LUT |     FF | BRAM | DSP | Pareto? |
| ------------ | -----------: | ---------: | -----: | -----: | ---: | --: | :-----: |
| SWâ€‘only      |    **27865** |          â€” |      â€” |      â€” |    â€” |   â€” |    âœ…    |
| HW v1        |        868.1 |        100 |  5â€¯971 |  6â€¯093 |    0 |  52 |    âœ…    |
| +CoeffÂ Cache |    **13.94** |        100 |  7â€¯237 |  9â€¯747 |   16 |  33 |    âŒ    |
| +RowÂ Cache   |        46.28 |        125 |  5â€¯883 |  9â€¯287 |   29 |  45 |    âœ…    |
| +ParallelÂ 4  |        11.11 |        125 | 10â€¯257 | 13â€¯946 |  102 |  58 |    âŒ    |
| **4b Trim**  |    **11.11** |        103 | 11â€¯721 | 16â€¯630 |   38 |  68 |    âœ…    |

*Throughput improves **2500Ã—** versus pure software while staying within 68â€¯DSPs.*

---

## ğŸ—‚ Directory Overview

```
lab_hw_sw_midterm-main/
â”œâ”€ hls/
â”‚  â”œâ”€ conv2d_hw.cpp  # kernel
â”‚  â”œâ”€ conv2d_hw.h    # typedefs
â”‚  â””â”€ script.tcl      # Vitis build
â”œâ”€ pynq/
â”‚  â”œâ”€ cnn_run.py     # host driver
â”‚  â””â”€ overlays/      # .bit + .hwh
â”œâ”€ data/             # test images
â””â”€ Lab_HW_SW_Midterm.pdf  # full report
```

---

## ğŸ“ˆ Lessons Learned

* **Burst length >128 beats** offered diminishing returns beyond 256 due to Zynq PSâ€‘PL interconnect.
* **`DATAFLOW` hazards:** arrayâ€‘partition conflicts caused writeâ€‘afterâ€‘read (WAR) violations; solved by manual pipelining instead.
* **Fixedâ€‘point scaling:** `ap_fixed<16,4>` chosen to keep DSP48 in multiplierâ€‘adder mode without extra fabric logic.

